# L3xbot ğŸš€  

## **Vision**  
L3xbot is an AI-driven robotic assistant designed to help the visually impaired "see" through advanced **computer vision, haptic feedback, and AI-powered speech processing**.  

## **Features**  
- ğŸ· **Object Recognition** â€“ Uses YOLO-based detection to identify objects in real-time.  
- ğŸ”Š **Speech Feedback** â€“ Converts detected objects into spoken descriptions using text-to-speech.  
- ğŸ“³ **Haptic Alerts** â€“ Sends vibration signals when obstacles are detected to assist navigation.  
- ğŸŒ **Accessible Design** â€“ Built with an intuitive user interface for seamless interaction.  

## **Tech Stack**  
- ğŸ”¹ **Python** â€“ Core language for AI processing  
- ğŸ”¹ **OpenCV** â€“ Image recognition and computer vision  
- ğŸ”¹ **YOLOv3** â€“ Deep learning model for object detection  
- ğŸ”¹ **Google Text-to-Speech (gTTS)** â€“ Voice feedback  
- ğŸ”¹ **Arduino/Raspberry Pi** â€“ Hardware integration for haptic feedback 
