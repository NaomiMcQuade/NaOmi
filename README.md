# L3xbot 🚀  

## **Vision**  
L3xbot is an AI-driven robotic assistant designed to help the visually impaired "see" through advanced **computer vision, haptic feedback, and AI-powered speech processing**.  

## **Features**  
- 🏷 **Object Recognition** – Uses YOLO-based detection to identify objects in real-time.  
- 🔊 **Speech Feedback** – Converts detected objects into spoken descriptions using text-to-speech.  
- 📳 **Haptic Alerts** – Sends vibration signals when obstacles are detected to assist navigation.  
- 🌍 **Accessible Design** – Built with an intuitive user interface for seamless interaction.  

## **Tech Stack**  
- 🔹 **Python** – Core language for AI processing  
- 🔹 **OpenCV** – Image recognition and computer vision  
- 🔹 **YOLOv3** – Deep learning model for object detection  
- 🔹 **Google Text-to-Speech (gTTS)** – Voice feedback  
- 🔹 **Arduino/Raspberry Pi** – Hardware integration for haptic feedback 
